{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARSA in windy gridworld\n",
    "***\n",
    "### The gridworld:\n",
    "<img src=\"https://www.researchgate.net/profile/Markus_Dumke/publication/320890681/figure/fig1/AS:763210537922560@1558974980641/The-windy-gridworld-task-The-goal-is-to-move-from-the-start-state-S-to-the-goal-state-G.jpg\" alt=\"The windy gridword\" title=\"Windy gridworld\" />\n",
    "\n",
    "#### Choice of actions:\n",
    " - 0: up\n",
    " - 1: down\n",
    " - 2: right\n",
    " - 3:left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# public variables about the env\n",
    "START_STATE = 30\n",
    "END_STATE = 37\n",
    "rows = 7\n",
    "columns = 10\n",
    "num_states = rows*columns\n",
    "num_actions = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windy(state):\n",
    "    col=state%10\n",
    "    if (col==6 or col==7):\n",
    "        return 2\n",
    "    elif (col>=3 and col<=5 or col==8):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def outside_limits(state):\n",
    "    if state<0 or state>69:\n",
    "        return True\n",
    "    else:\n",
    "        return False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_step(state, action):\n",
    "    wind = windy(state)\n",
    "    #transition to next state depending on action and wind in current state\n",
    "    if action==0 :\n",
    "        next_state = state - columns - wind*columns\n",
    "        while outside_limits(next_state):\n",
    "            next_state = next_state + columns\n",
    "    elif action==1 :\n",
    "        next_state = state + columns\n",
    "        if outside_limits(next_state):\n",
    "            next_state=state\n",
    "        next_state -= wind*columns\n",
    "        while outside_limits(next_state):\n",
    "            next_state = next_state + columns\n",
    "    elif action==2 :\n",
    "        next_state = state + 1\n",
    "        if state%columns==9:\n",
    "            next_state=state\n",
    "        next_state -= wind*columns\n",
    "        while outside_limits(next_state):\n",
    "            next_state = next_state + columns\n",
    "    elif action==3 :\n",
    "        next_state = state - 1\n",
    "        if state%columns==0:\n",
    "            next_state=state\n",
    "        next_state -= wind*columns\n",
    "        while outside_limits(next_state):\n",
    "            next_state = next_state + columns\n",
    "    # reward at each time step is -1 until the goal is reached\n",
    "    reward = -1\n",
    "    return [next_state, reward]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa(alpha, epsilon, gamma, episodes) :\n",
    "    Q = np.zeros((num_states,num_actions))\n",
    "    for episode in range(episodes):\n",
    "        curr_state = START_STATE\n",
    "        # choosing action based on epsion greedy policy over Q\n",
    "        if np.random.random()>epsilon:\n",
    "            # exploit greedy action\n",
    "            curr_action = np.argmax(Q[curr_state])\n",
    "        else:\n",
    "            #explore random action\n",
    "            curr_action = np.random.randint(0,num_actions)\n",
    "        while curr_state!=END_STATE:\n",
    "            next_state, reward = env_step(curr_state, curr_action)\n",
    "            # choosing next action based on epsilon greedy poicy over Q\n",
    "            if np.random.random()>epsilon:\n",
    "                next_action = np.argmax(Q[next_state])\n",
    "            else:\n",
    "                next_action = np.random.randint(0, num_actions)\n",
    "            # updating Q\n",
    "            Q[curr_state, curr_action] += alpha*(reward + gamma*Q[next_state, next_action] - Q[curr_state, curr_action])\n",
    "            curr_state = next_state\n",
    "            curr_action = next_action\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_policy(Q):\n",
    "    pi = np.zeros((rows, columns))\n",
    "    for state in range(num_states):\n",
    "        pi[int(state/10)][state%10] = np.argmax(Q[state])\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# public variables setting the parameters\n",
    "alpha = 0.5\n",
    "epsilon = 0.1\n",
    "gamma = 1 # undiscounted task\n",
    "episodes = 800000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value function after sarsa:  \n",
      "\n",
      " [[-20.30219889 -20.65936121 -18.55421062 -20.45589392]\n",
      " [-20.09156595 -19.67884434 -17.44371898 -19.7732199 ]\n",
      " [-17.71814819 -17.93670987 -15.58741699 -18.68159937]\n",
      " [-16.12701517 -15.56078134 -14.58244986 -17.73387109]\n",
      " [-15.81661437 -15.33672106 -12.7893856  -15.79473408]\n",
      " [-15.51905613 -13.44412248 -12.09659627 -15.83354408]\n",
      " [-13.68131517 -12.00870231 -10.9804696  -14.85360932]\n",
      " [-11.54290526 -11.53215966  -9.1697782  -13.5167977 ]\n",
      " [-11.13897925 -10.14236146  -7.93300637 -12.15447049]\n",
      " [ -9.35684336  -6.92148078 -10.98270021 -11.44387474]\n",
      " [-20.52600076 -20.13126318 -18.33505203 -20.93987213]\n",
      " [-19.35220852 -20.01466013 -17.75751441 -20.50560417]\n",
      " [-16.45987395 -17.65477595 -17.38256435 -18.66566274]\n",
      " [-15.37974363 -16.00717456 -15.59956937 -17.63946682]\n",
      " [-14.91969845 -14.80911947 -12.93887627 -15.05878569]\n",
      " [-13.9777817  -13.23460499 -12.33113867 -15.19465275]\n",
      " [-12.21914113 -12.50491482 -10.30209844 -12.23172579]\n",
      " [-12.11806246 -11.58631735  -9.24369533 -12.20355099]\n",
      " [-11.49507225 -12.21833332 -10.84772976 -12.99846589]\n",
      " [-10.22280532  -5.41565336  -9.21126492 -11.75537023]\n",
      " [-20.63843385 -21.10999624 -18.61290861 -20.8816261 ]\n",
      " [-18.46027037 -19.69600893 -16.61459309 -20.99283297]\n",
      " [-17.52925396 -17.42725971 -15.49934116 -19.63499928]\n",
      " [-15.63167809 -16.1092976  -14.2700538  -16.5412867 ]\n",
      " [-13.91431529 -14.89992249 -13.00190652 -16.04641432]\n",
      " [-14.35712759 -13.40888959 -11.04051798 -14.85467453]\n",
      " [-13.62797236 -12.40973431  -9.98042106 -13.07902406]\n",
      " [-12.29376583 -12.63213578  -9.92002081 -13.28526914]\n",
      " [-11.27303697 -10.37323549  -9.15652511 -10.74154994]\n",
      " [ -9.00607167  -4.01472265  -7.06328755 -10.04765585]\n",
      " [-20.20553714 -20.06827238 -18.42826316 -19.63772468]\n",
      " [-18.49537927 -18.47055384 -17.33231326 -20.34625398]\n",
      " [-17.26010248 -16.69572562 -15.09889064 -19.39587483]\n",
      " [-15.52112361 -15.37710307 -13.89729941 -16.75863639]\n",
      " [-14.69934613 -14.81476851 -12.42662537 -15.51416376]\n",
      " [-14.434478   -14.16538135 -10.98537577 -15.20374092]\n",
      " [-13.65218772 -12.49395511 -12.2033519  -13.13584149]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [-11.64604415  -9.83509304  -7.94390714 -10.69485483]\n",
      " [ -8.90794586  -3.00211769  -6.81079476  -8.91893746]\n",
      " [-21.12505501 -20.56705445 -18.38016607 -19.44203709]\n",
      " [-20.43805628 -19.5262325  -16.86488463 -20.49100579]\n",
      " [-16.97782608 -17.31742107 -14.81723215 -19.08977584]\n",
      " [-16.29236009 -15.75559416 -13.58289436 -17.44779501]\n",
      " [-16.11830195 -14.93024325 -12.47902886 -17.14322685]\n",
      " [-13.97440679 -14.01681974 -12.57331826 -14.88456275]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [-11.68145192  -1.          -8.92984976 -13.18548988]\n",
      " [-10.10734733  -2.00123925  -4.48770885  -1.        ]\n",
      " [ -7.45091689  -8.16983257  -7.28822702  -2.00014234]\n",
      " [-21.05649604 -19.73065246 -21.24427489 -21.57608621]\n",
      " [-20.0040078  -20.75886072 -17.61614084 -20.50365654]\n",
      " [-18.00500385 -17.44899298 -16.353588   -19.71411595]\n",
      " [-15.9793545  -16.87591941 -14.03300739 -16.83614479]\n",
      " [-15.05524877 -15.29676608 -14.39287958 -16.27259014]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [-13.26125226 -11.20932482 -10.80584139 -13.1176903 ]\n",
      " [ -9.02944584  -8.51494963  -5.37222237  -8.51088018]\n",
      " [ -4.46752897  -9.47904086  -8.9159503   -8.273291  ]\n",
      " [-21.53653812 -20.023355   -18.59770421 -20.87998339]\n",
      " [-19.75990981 -18.2359612  -17.58656831 -20.81674705]\n",
      " [-18.16313958 -17.93416113 -16.52472971 -18.99014279]\n",
      " [-16.44165803 -16.48861238 -15.52644502 -17.63581089]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [ -4.31484136  -7.57075305  -7.70504746 -12.70367344]\n",
      " [ -8.52164969 -10.00469993  -8.81598572  -9.86915572]]\n"
     ]
    }
   ],
   "source": [
    "value_func = sarsa(alpha, epsilon, gamma, episodes)\n",
    "print (\"value function after sarsa:  \\n\\n\", value_func )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy learnt: \n",
      "\n",
      " [[2. 2. 2. 2. 2. 2. 2. 2. 2. 1.]\n",
      " [2. 2. 0. 0. 2. 2. 2. 2. 2. 1.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 1.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 0. 2. 1.]\n",
      " [2. 2. 2. 2. 2. 2. 0. 1. 3. 3.]\n",
      " [1. 2. 2. 2. 2. 0. 0. 2. 2. 0.]\n",
      " [2. 2. 2. 2. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "policy = greedy_policy(value_func)\n",
    "print (\"policy learnt: \\n\\n\", policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual of the policy learnt:\n",
    "<img src=\"https://4.bp.blogspot.com/-nLpJR9NEvxA/W5FpxNVQu-I/AAAAAAAAAd8/NN0J3zNDXM0W0KLHvWIPpzGffBpYlEI3wCLcBGAs/s320/Capture.PNG\" alt=\"The windy gridword\" title=\"Windy gridworld\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(policy):\n",
    "    curr_state = START_STATE\n",
    "    R = 0\n",
    "    while curr_state!=END_STATE:\n",
    "        curr_state,reward= env_step(curr_state, policy[int(curr_state/10)][curr_state%10])\n",
    "        R+=reward\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return from following optimal policy:  -15\n"
     ]
    }
   ],
   "source": [
    "print (\"return from following optimal policy: \", run(policy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
